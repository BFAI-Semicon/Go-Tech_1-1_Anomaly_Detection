from __future__ import annotations

import json
import os
import time
from collections.abc import Iterable
from typing import Any, cast

import requests

try:  # Streamlitã¯å®Ÿè¡Œæ™‚ã«ã®ã¿å¿…è¦ã€‚ãƒ†ã‚¹ãƒˆã§ã¯æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã‚‚å‹•ä½œã•ã›ã‚‹ã€‚
    import streamlit as st  # type: ignore[import-not-found]
except ImportError:  # pragma: no cover - ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã¯streamlitãŒç„¡ã„ã“ã¨ã‚’è¨±å®¹
    st = None  # type: ignore[assignment]


def build_mlflow_run_link(mlflow_url: str, run_id: str) -> str:
    """MLflow UI ã® run ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    base = mlflow_url.rstrip("/")
    return f"{base}/#/experiments/1/runs/{run_id}"


def submit_submission(
    api_url: str,
    token: str,
    files: Iterable[tuple[str, Any, str]],
    entrypoint: str = "main.py",
    config_file: str = "config.yaml",
    metadata: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """POST /submissions ã‚’å‘¼ã³å‡ºã—ã¦ submission_id ã‚’å–å¾—ã™ã‚‹ã€‚"""
    url = api_url.rstrip("/") + "/submissions"
    headers = {"Authorization": f"Bearer {token}"}
    data = {
        "entrypoint": entrypoint,
        "config_file": config_file,
        "metadata": json.dumps(metadata or {}),
    }
    response = requests.post(url, headers=headers, files=[("files", f) for f in files], data=data, timeout=30)
    response.raise_for_status()
    return response.json()


def create_job(api_url: str, token: str, submission_id: str, config: dict[str, Any]) -> dict[str, Any]:
    """POST /jobs ã‚’å‘¼ã³å‡ºã—ã¦ job_id ã‚’å–å¾—ã™ã‚‹ã€‚"""
    url = api_url.rstrip("/") + "/jobs"
    headers = {"Authorization": f"Bearer {token}"}
    payload = {"submission_id": submission_id, "config": config}
    response = requests.post(url, json=payload, headers=headers, timeout=30)
    response.raise_for_status()
    return response.json()


def fetch_job_status(api_url: str, token: str, job_id: str) -> dict[str, Any] | None:
    """GET /jobs/{job_id}/status ã‚’å–å¾—ã™ã‚‹ã€‚"""
    url = api_url.rstrip("/") + f"/jobs/{job_id}/status"
    headers = {"Authorization": f"Bearer {token}"}
    response = requests.get(url, headers=headers, timeout=15)
    if response.status_code == 404:
        return None
    response.raise_for_status()
    return response.json()


def fetch_job_logs(api_url: str, token: str, job_id: str) -> str:
    """GET /jobs/{job_id}/logs ã‚’å–å¾—ã™ã‚‹ã€‚"""
    url = api_url.rstrip("/") + f"/jobs/{job_id}/logs"
    headers = {"Authorization": f"Bearer {token}"}
    response = requests.get(url, headers=headers, timeout=15)
    response.raise_for_status()
    return response.text


def add_job_to_state(state: dict[str, Any], job: dict[str, Any]) -> list[dict[str, Any]]:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®ã‚¸ãƒ§ãƒ–ä¸€è¦§ã‚’å…ˆé ­æŒ¿å…¥ã—ã€é‡è¤‡ã¯å‰æ–¹ã«å¯„ã›ã‚‹ã€‚"""
    jobs: list[dict[str, Any]] = state.setdefault("jobs", [])
    job_id = job.get("job_id")
    if job_id:
        jobs = [j for j in jobs if j.get("job_id") != job_id]
    jobs.insert(0, job)
    state["jobs"] = jobs
    return jobs


def has_running_jobs(jobs: list[dict[str, Any]]) -> bool:
    """å®Ÿè¡Œä¸­ï¼ˆpending/runningï¼‰ã®ã‚¸ãƒ§ãƒ–ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã™ã‚‹ã€‚"""
    return any(job.get("status") in ("pending", "running") for job in jobs)


def get_status_color(status: str) -> str:
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ãŸçµµæ–‡å­—ã‚’è¿”ã™ã€‚"""
    if status == "completed":
        return "âœ…"
    elif status == "failed":
        return "âŒ"
    elif status in ("pending", "running"):
        return "â³"
    else:
        return "â“"


def add_submission_file(
    api_url: str,
    token: str,
    submission_id: str,
    file: Any,
    max_retries: int = 3,
) -> dict[str, Any]:
    """
    submissionã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤è¿½åŠ ã™ã‚‹ï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰ã€‚

    Args:
        api_url: API URL
        token: èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³
        submission_id: submission ID
        file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
        max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°

    Returns:
        {"filename": str, "size": int}

    Raises:
        requests.HTTPError: 4xxã‚¨ãƒ©ãƒ¼ï¼ˆãƒªãƒˆãƒ©ã‚¤ãªã—ï¼‰
        Exception: ãƒªãƒˆãƒ©ã‚¤3å›å¤±æ•—å¾Œ
    """
    url = f"{api_url.rstrip('/')}/submissions/{submission_id}/files"
    headers = {"Authorization": f"Bearer {token}"}

    for attempt in range(max_retries):
        file.seek(0)  # Reset file pointer to beginning for retry
        try:
            files_payload = {"file": (file.name, file, file.type)}
            response = requests.post(url, headers=headers, files=files_payload, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.HTTPError as exc:
            if 400 <= exc.response.status_code < 500:
                # 4xxã‚¨ãƒ©ãƒ¼: ãƒªãƒˆãƒ©ã‚¤ã—ãªã„
                raise
            if attempt < max_retries - 1:
                # 5xxã‚¨ãƒ©ãƒ¼: ãƒªãƒˆãƒ©ã‚¤
                time.sleep(2 ** attempt)  # Exponential backoff
                continue
            raise Exception("Max retries exceeded") from exc
        except Exception as exc:
            if attempt < max_retries - 1:
                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼: ãƒªãƒˆãƒ©ã‚¤
                time.sleep(2 ** attempt)
                continue
            raise Exception("Max retries exceeded") from exc

    raise Exception("Max retries exceeded")


def submit_files_sequentially(
    api_url: str,
    token: str,
    files: list[Any],
    entrypoint: str,
    config_file: str,
    metadata: dict[str, Any],
) -> str:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †æ¬¡ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚

    Args:
        api_url: API URL
        token: èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³
        files: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
        entrypoint: ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å
        config_file: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å
        metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

    Returns:
        submission_id: ä½œæˆã•ã‚ŒãŸsubmission ID

    Raises:
        Exception: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—
    """
    if not files:
        raise ValueError("No files to upload")

    # Streamlit UIè¦ç´ ï¼ˆãƒ†ã‚¹ãƒˆæ™‚ã¯Noneï¼‰
    progress_placeholder = None
    if st is not None:
        progress_placeholder = st.empty()

    # æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã§submissionä½œæˆ
    first_file = files[0]
    files_payload = [(first_file.name, first_file, first_file.type or "application/octet-stream")]
    submission = submit_submission(
        api_url=api_url,
        token=token,
        files=files_payload,
        entrypoint=entrypoint,
        config_file=config_file,
        metadata=metadata,
    )
    submission_id = submission["submission_id"]

    # é€²æ—è¡¨ç¤º
    if progress_placeholder is not None:
        progress_placeholder.info(f"1/{len(files)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")

    # 2ç•ªç›®ä»¥é™ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †æ¬¡ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    for i, file in enumerate(files[1:], start=2):
        try:
            if progress_placeholder is not None:
                progress_placeholder.info(f"{i}/{len(files)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
            add_submission_file(api_url, token, submission_id, file)
        except Exception as exc:
            error_msg = f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {file.name} - {exc}"
            if progress_placeholder is not None:
                progress_placeholder.error(error_msg)
            raise Exception(error_msg) from exc

    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if progress_placeholder is not None:
        progress_placeholder.success(f"å…¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{len(files)}ä»¶ï¼‰ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    return submission_id


def _render_submission_form(api_url: str, mlflow_url: str) -> None:
    if st is None:  # pragma: no cover
        raise RuntimeError("streamlit is not installed. Install it to run the UI.")

    st.header("Submission")
    token = st.text_input("API Token", type="password", key="token_input")
    uploaded_files = st.file_uploader("Upload files (main.py, config.yaml, etc.)", accept_multiple_files=True)
    entrypoint = st.text_input("Entrypoint", value="main.py")
    config_file = st.text_input("Config file", value="config.yaml")
    metadata_text = st.text_area("metadata (JSON)", value='{"method":"padim"}')

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†çŠ¶æ…‹ã®å–å¾—
    upload_complete = st.session_state.get("upload_complete", False)
    submission_id = st.session_state.get("submission_id")

    # Submitãƒœã‚¿ãƒ³ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ï¼‰
    submit_disabled = st.session_state.get("uploading", False)
    if st.button("Submit", type="primary", disabled=submit_disabled):
        if not token:
            st.error("API Tokenã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        if not uploaded_files:
            st.error("å°‘ãªãã¨ã‚‚1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            return
        try:
            metadata = json.loads(metadata_text) if metadata_text.strip() else {}
        except json.JSONDecodeError:
            st.error("metadata ã¯ JSON å½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹
        st.session_state["uploading"] = True
        st.session_state["upload_complete"] = False

        try:
            # é †æ¬¡ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
            submission_id = submit_files_sequentially(
                api_url=api_url,
                token=token,
                files=uploaded_files,
                entrypoint=entrypoint,
                config_file=config_file,
                metadata=metadata,
            )
            st.session_state["submission_id"] = submission_id
            st.session_state["upload_complete"] = True
            st.success(f"Submission created: {submission_id}")
            st.rerun()  # UIæ›´æ–°
        except Exception as exc:  # pragma: no cover - UIçµŒç”±ã®ã¿
            st.error(f"Submission failed: {exc}")
        finally:
            st.session_state["uploading"] = False

    # ã‚¸ãƒ§ãƒ–æŠ•å…¥ãƒœã‚¿ãƒ³ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†å¾Œã«æœ‰åŠ¹åŒ–ï¼‰
    if upload_complete and submission_id:
        if st.button("Enqueue Job", type="secondary"):
            try:
                job_resp = create_job(
                    api_url=api_url,
                    token=token,
                    submission_id=submission_id,
                    config={"resource_class": "medium"},
                )
                job_info = {
                    "job_id": job_resp.get("job_id"),
                    "submission_id": submission_id,
                    "status": job_resp.get("status", "pending"),
                    "mlflow_url": mlflow_url,
                }
                add_job_to_state(st.session_state, job_info)
                st.success(f"Job enqueued: {job_info['job_id']}")
                # ã‚¸ãƒ§ãƒ–æŠ•å…¥å¾Œã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                st.session_state["upload_complete"] = False
                st.session_state["submission_id"] = None
            except Exception as exc:  # pragma: no cover
                st.error(f"Job enqueue failed: {exc}")

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã®çŠ¶æ…‹è¡¨ç¤º
    if st.session_state.get("uploading"):
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ã®çŠ¶æ…‹è¡¨ç¤º
    if upload_complete:
        st.success("å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã‚¸ãƒ§ãƒ–ã‚’æŠ•å…¥ã—ã¦ãã ã•ã„ã€‚")


def _render_jobs(api_url: str, mlflow_url: str) -> None:
    if st is None:  # pragma: no cover
        return

    st.header("ã‚¸ãƒ§ãƒ–ä¸€è¦§")
    token = st.session_state.get("token_input", "")
    jobs: list[dict[str, Any]] = st.session_state.get("jobs", [])
    if not jobs:
        st.info("ã¾ã ã‚¸ãƒ§ãƒ–ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰æŠ•ç¨¿ã—ã¦ãã ã•ã„ã€‚")
        return

    # å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ã®æ¤œå‡ºç”¨ï¼ˆæœ€åˆã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰åˆ¤å®šï¼‰
    has_pending_or_running = any(
        job.get("status") in ("pending", "running") for job in jobs
    )

    # å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ãŒãªã„å ´åˆã¯ã€APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
    fetch_status = has_pending_or_running
    running_jobs_detected = False

    for job in list(jobs):
        job_id = cast(str | None, job.get("job_id"))
        submission_id = job.get("submission_id")
        col1, col2, col3 = st.columns([3, 3, 2])
        with col1:
            st.markdown(f"**Job ID:** {job_id}")
            st.caption(f"Submission: {submission_id}")
        with col2:
            status_data = None
            # å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ãŒã‚ã‚‹å ´åˆã®ã¿APIã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
            if fetch_status and token and job_id:
                try:
                    status_data = fetch_job_status(api_url, token, job_id)
                except Exception:  # pragma: no cover
                    status_data = None
            status_text = str(status_data.get("status") if status_data else job.get("status", "unknown"))

            # å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ã®æ¤œå‡º
            if status_text in ("pending", "running"):
                running_jobs_detected = True

            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºï¼ˆè‰²åˆ†ã‘ï¼‰
            emoji = get_status_color(status_text)
            st.markdown(f"{emoji} **{status_text}**")

            if status_data and status_data.get("run_id"):
                link = build_mlflow_run_link(mlflow_url, status_data["run_id"])
                st.markdown(f"[MLflow run]({link})")
        with col3:
            # å®Ÿè¡Œä¸­ã¾ãŸã¯pendingã®å ´åˆã¯çŠ¶æ…‹ã‚’è¡¨ç¤º
            if status_text in ("pending", "running"):
                st.caption(f"â³ {status_text}...")
            elif status_text in ("completed", "failed"):
                # ã‚¸ãƒ§ãƒ–ãŒçµ‚äº†ã—ã¦ã„ã‚‹å ´åˆã€expanderã§ãƒ­ã‚°ã‚’è¡¨ç¤ºï¼ˆè‡ªå‹•æ›´æ–°ã§é–‰ã˜ãªã„ï¼‰
                with st.expander("ğŸ“‹ View Logs", expanded=False):
                    if not token:
                        st.warning("API TokenãŒå¿…è¦ã§ã™")
                    elif not job_id:
                        st.warning("Job ID ãŒã‚ã‚Šã¾ã›ã‚“")
                    else:
                        try:
                            logs = fetch_job_logs(api_url, token, job_id)
                            st.text_area(
                                "Job Logs",
                                logs,
                                height=400,
                                key=f"logs-content-{job_id}",
                                label_visibility="collapsed"
                            )
                        except Exception as exc:  # pragma: no cover
                            st.error(f"ãƒ­ã‚°å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
            else:
                st.caption(f"Status: {status_text}")

    # è‡ªå‹•æ›´æ–°ã®çŠ¶æ…‹è¡¨ç¤º
    if running_jobs_detected:
        st.caption("â³ å®Ÿè¡Œä¸­ã®ã‚¸ãƒ§ãƒ–ãŒã‚ã‚Šã¾ã™ã€‚5ç§’ã”ã¨ã«è‡ªå‹•æ›´æ–°ã•ã‚Œã¾ã™ã€‚")
    elif jobs:
        # å…¨ã‚¸ãƒ§ãƒ–ãŒçµ‚äº†ã—ã¦ã„ã‚‹å ´åˆ
        st.caption("âœ… å…¨ã¦ã®ã‚¸ãƒ§ãƒ–ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚æ–°ã—ã„ã‚¸ãƒ§ãƒ–ã‚’æŠ•ç¨¿ã™ã‚‹ã¨è‡ªå‹•æ›´æ–°ãŒå†é–‹ã•ã‚Œã¾ã™ã€‚")


def main() -> None:  # pragma: no cover - UIèµ·å‹•æ™‚ã«å®Ÿè¡Œ
    if st is None:
        raise RuntimeError("streamlit is not installed. Install it to run the UI.")

    st.set_page_config(page_title="LeadersBoard", layout="wide")
    api_url = os.getenv("API_URL", "http://api:8010")
    mlflow_url = os.getenv("MLFLOW_URL", "http://mlflow:5010")

    _render_submission_form(api_url, mlflow_url)
    st.divider()

    # Fragmentè‡ªå‹•æ›´æ–°ã‚’é©ç”¨ï¼ˆãŸã ã—å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ãŒãªã„å ´åˆã¯APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    render_jobs_with_auto_refresh = st.fragment(run_every="5s")(_render_jobs)
    render_jobs_with_auto_refresh(api_url, mlflow_url)


if __name__ == "__main__":  # pragma: no cover
    main()
