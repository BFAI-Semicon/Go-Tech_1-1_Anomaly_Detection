from __future__ import annotations

import json
import os
from collections.abc import Iterable
from typing import Any, cast

import requests

try:  # Streamlitã¯å®Ÿè¡Œæ™‚ã«ã®ã¿å¿…è¦ã€‚ãƒ†ã‚¹ãƒˆã§ã¯æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã‚‚å‹•ä½œã•ã›ã‚‹ã€‚
    import streamlit as st  # type: ignore[import-not-found]
except ImportError:  # pragma: no cover - ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã¯streamlitãŒç„¡ã„ã“ã¨ã‚’è¨±å®¹
    st = None  # type: ignore[assignment]


def build_mlflow_run_link(mlflow_url: str, run_id: str) -> str:
    """MLflow UI ã® run ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    base = mlflow_url.rstrip("/")
    return f"{base}/#/experiments/1/runs/{run_id}"


def submit_submission(
    api_url: str,
    token: str,
    files: Iterable[tuple[str, Any, str]],
    entrypoint: str = "main.py",
    config_file: str = "config.yaml",
    metadata: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """POST /submissions ã‚’å‘¼ã³å‡ºã—ã¦ submission_id ã‚’å–å¾—ã™ã‚‹ã€‚"""
    url = api_url.rstrip("/") + "/submissions"
    headers = {"Authorization": f"Bearer {token}"}
    data = {
        "entrypoint": entrypoint,
        "config_file": config_file,
        "metadata": json.dumps(metadata or {}),
    }
    response = requests.post(
        url, headers=headers, files=[("files", f) for f in files], data=data, timeout=30
    )
    response.raise_for_status()
    return response.json()


def create_job(
    api_url: str, token: str, submission_id: str, config: dict[str, Any]
) -> dict[str, Any]:
    """POST /jobs ã‚’å‘¼ã³å‡ºã—ã¦ job_id ã‚’å–å¾—ã™ã‚‹ã€‚"""
    url = api_url.rstrip("/") + "/jobs"
    headers = {"Authorization": f"Bearer {token}"}
    payload = {"submission_id": submission_id, "config": config}
    response = requests.post(url, json=payload, headers=headers, timeout=30)
    response.raise_for_status()
    return response.json()


def fetch_job_status(api_url: str, token: str, job_id: str) -> dict[str, Any] | None:
    """GET /jobs/{job_id}/status ã‚’å–å¾—ã™ã‚‹ã€‚"""
    url = api_url.rstrip("/") + f"/jobs/{job_id}/status"
    headers = {"Authorization": f"Bearer {token}"}
    response = requests.get(url, headers=headers, timeout=15)
    if response.status_code == 404:
        return None
    response.raise_for_status()
    return response.json()


def fetch_job_logs(api_url: str, token: str, job_id: str, tail_lines: int | None = None) -> str:
    """GET /jobs/{job_id}/logs ã‚’å–å¾—ã™ã‚‹ã€‚

    Args:
        api_url: API URL
        token: èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³
        job_id: ã‚¸ãƒ§ãƒ–ID
        tail_lines: å–å¾—ã™ã‚‹æœ€çµ‚è¡Œæ•°ï¼ˆçœç•¥æ™‚ã¯å…¨è¡Œï¼‰
    """
    url = api_url.rstrip("/") + f"/jobs/{job_id}/logs"
    headers = {"Authorization": f"Bearer {token}"}
    params: dict[str, int] = {}
    if tail_lines is not None:
        params["tail_lines"] = tail_lines
    response = requests.get(url, headers=headers, params=params, timeout=15)
    response.raise_for_status()
    data = response.json()
    return data.get("logs", "")


def add_job_to_state(state: dict[str, Any], job: dict[str, Any]) -> list[dict[str, Any]]:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®ã‚¸ãƒ§ãƒ–ä¸€è¦§ã‚’å…ˆé ­æŒ¿å…¥ã—ã€é‡è¤‡ã¯å‰æ–¹ã«å¯„ã›ã‚‹ã€‚"""
    jobs: list[dict[str, Any]] = state.setdefault("jobs", [])
    job_id = job.get("job_id")
    if job_id:
        jobs = [j for j in jobs if j.get("job_id") != job_id]
    jobs.insert(0, job)
    state["jobs"] = jobs
    return jobs


def has_running_jobs(jobs: list[dict[str, Any]]) -> bool:
    """å®Ÿè¡Œä¸­ï¼ˆpending/runningï¼‰ã®ã‚¸ãƒ§ãƒ–ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã™ã‚‹ã€‚"""
    return any(job.get("status") in ("pending", "running") for job in jobs)


def get_status_color(status: str) -> str:
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ãŸçµµæ–‡å­—ã‚’è¿”ã™ã€‚"""
    if status == "completed":
        return "âœ…"
    elif status == "failed":
        return "âŒ"
    elif status in ("pending", "running"):
        return "â³"
    else:
        return "â“"


def _render_submission_form(api_url: str, mlflow_url: str) -> None:
    if st is None:  # pragma: no cover
        raise RuntimeError("streamlit is not installed. Install it to run the UI.")

    st.header("Submission")
    token = st.text_input("API Token", type="password", key="token_input")
    uploaded_files = st.file_uploader(
        "Upload files (main.py, config.yaml, etc.)", accept_multiple_files=True
    )
    entrypoint = st.text_input("Entrypoint", value="main.py")
    config_file = st.text_input("Config file", value="config.yaml")
    metadata_text = st.text_area("metadata (JSON)", value='{"method":"padim"}')

    if st.button("Submit", type="primary"):
        if not token:
            st.error("API Tokenã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        if not uploaded_files:
            st.error("å°‘ãªãã¨ã‚‚1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            return
        try:
            metadata = json.loads(metadata_text) if metadata_text.strip() else {}
        except json.JSONDecodeError:
            st.error("metadata ã¯ JSON å½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        files_payload = [(f.name, f, f.type or "application/octet-stream") for f in uploaded_files]
        try:
            submission = submit_submission(
                api_url=api_url,
                token=token,
                files=files_payload,
                entrypoint=entrypoint,
                config_file=config_file,
                metadata=metadata,
            )
            submission_id = submission["submission_id"]
            st.success(f"Submission created: {submission_id}")
        except Exception as exc:  # pragma: no cover - UIçµŒç”±ã®ã¿
            st.error(f"Submission failed: {exc}")
            return

        # ã‚¸ãƒ§ãƒ–æŠ•å…¥
        try:
            job_resp = create_job(
                api_url=api_url,
                token=token,
                submission_id=submission_id,
                config={"resource_class": "medium"},
            )
            job_info = {
                "job_id": job_resp.get("job_id"),
                "submission_id": submission_id,
                "status": job_resp.get("status", "pending"),
                "mlflow_url": mlflow_url,
            }
            add_job_to_state(st.session_state, job_info)
            st.success(f"Job enqueued: {job_info['job_id']}")
        except Exception as exc:  # pragma: no cover
            st.error(f"Job enqueue failed: {exc}")


def _render_job_logs(
    api_url: str,
    token: str,
    job_id: str,
    is_running: bool,
) -> None:
    """ã‚¸ãƒ§ãƒ–ã®ãƒ­ã‚°ã‚’è¡¨ç¤ºã™ã‚‹ã€‚

    Args:
        api_url: API URL
        token: èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³
        job_id: ã‚¸ãƒ§ãƒ–ID
        is_running: å®Ÿè¡Œä¸­ã‹ã©ã†ã‹
    """
    if st is None:  # pragma: no cover
        return

    if not token:
        st.warning("API TokenãŒå¿…è¦ã§ã™")
        return

    # å®Ÿè¡Œä¸­ã®ã‚¸ãƒ§ãƒ–ã¯æœ€æ–°100è¡Œã®ã¿å–å¾—ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
    tail_lines = 100 if is_running else None

    try:
        logs = fetch_job_logs(api_url, token, job_id, tail_lines=tail_lines)
        if logs:
            st.code(logs, language="log", line_numbers=True)
            if is_running and tail_lines:
                st.caption(f"æœ€æ–° {tail_lines} è¡Œã‚’è¡¨ç¤ºä¸­ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ï¼‰")
        else:
            st.info("ãƒ­ã‚°ã¯ã¾ã å‡ºåŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    except Exception as exc:  # pragma: no cover
        st.error(f"ãƒ­ã‚°å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")


def _render_jobs(api_url: str, mlflow_url: str) -> None:
    if st is None:  # pragma: no cover
        return

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã¨æ‰‹å‹•æ›´æ–°ãƒœã‚¿ãƒ³
    header_col, refresh_col = st.columns([6, 1])
    with header_col:
        st.header("ã‚¸ãƒ§ãƒ–ä¸€è¦§")
    with refresh_col:
        if st.button("ğŸ”„", help="æ‰‹å‹•æ›´æ–°"):
            st.rerun()

    token = st.session_state.get("token_input", "")
    jobs: list[dict[str, Any]] = st.session_state.get("jobs", [])
    if not jobs:
        st.info("ã¾ã ã‚¸ãƒ§ãƒ–ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰æŠ•ç¨¿ã—ã¦ãã ã•ã„ã€‚")
        return

    # å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ã®æ¤œå‡ºç”¨ï¼ˆæœ€åˆã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰åˆ¤å®šï¼‰
    has_pending_or_running = any(job.get("status") in ("pending", "running") for job in jobs)

    # å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ãŒãªã„å ´åˆã¯ã€APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
    fetch_status = has_pending_or_running
    running_jobs_detected = False

    for job in list(jobs):
        job_id = cast(str | None, job.get("job_id"))
        submission_id = job.get("submission_id")

        # ã‚¸ãƒ§ãƒ–ã‚«ãƒ¼ãƒ‰ã®è¡¨ç¤º
        with st.container():
            col1, col2 = st.columns([3, 5])
            with col1:
                st.markdown(f"**Job ID:** `{job_id}`")
                st.caption(f"Submission: {submission_id}")

            with col2:
                status_data = None
                # å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ãŒã‚ã‚‹å ´åˆã®ã¿APIã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
                if fetch_status and token and job_id:
                    try:
                        status_data = fetch_job_status(api_url, token, job_id)
                    except Exception:  # pragma: no cover
                        status_data = None
                status_text = str(
                    status_data.get("status") if status_data else job.get("status", "unknown")
                )

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’æ›´æ–°
                job["status"] = status_text

                # å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ã®æ¤œå‡º
                if status_text in ("pending", "running"):
                    running_jobs_detected = True

                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºï¼ˆè‰²åˆ†ã‘ï¼‰
                emoji = get_status_color(status_text)
                st.markdown(f"{emoji} **{status_text}**")

                if status_data and status_data.get("run_id"):
                    link = build_mlflow_run_link(mlflow_url, status_data["run_id"])
                    st.markdown(f"[MLflow run]({link})")

            # ãƒ­ã‚°è¡¨ç¤ºã‚¨ãƒªã‚¢
            if job_id:
                is_running = status_text == "running"
                is_completed = status_text in ("completed", "failed")

                if is_running:
                    # å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ã‚’è¡¨ç¤º
                    with st.expander("ğŸ“‹ å®Ÿè¡Œä¸­ã®ãƒ­ã‚°", expanded=True):
                        _render_job_logs(api_url, token, job_id, is_running=True)
                elif is_completed:
                    # å®Œäº†/å¤±æ•—ã‚¸ãƒ§ãƒ–ã¯æŠ˜ã‚ŠãŸãŸã¿ã§ãƒ­ã‚°ã‚’è¡¨ç¤º
                    with st.expander("ğŸ“‹ ãƒ­ã‚°ã‚’è¡¨ç¤º", expanded=False):
                        _render_job_logs(api_url, token, job_id, is_running=False)

            st.divider()

    # è‡ªå‹•æ›´æ–°ã®çŠ¶æ…‹è¡¨ç¤º
    if running_jobs_detected:
        st.caption("â³ å®Ÿè¡Œä¸­ã®ã‚¸ãƒ§ãƒ–ãŒã‚ã‚Šã¾ã™ã€‚5ç§’ã”ã¨ã«è‡ªå‹•æ›´æ–°ã•ã‚Œã¾ã™ã€‚")
    elif jobs:
        # å…¨ã‚¸ãƒ§ãƒ–ãŒçµ‚äº†ã—ã¦ã„ã‚‹å ´åˆ
        st.caption(
            "âœ… å…¨ã¦ã®ã‚¸ãƒ§ãƒ–ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚æ–°ã—ã„ã‚¸ãƒ§ãƒ–ã‚’æŠ•ç¨¿ã™ã‚‹ã¨è‡ªå‹•æ›´æ–°ãŒå†é–‹ã•ã‚Œã¾ã™ã€‚"
        )


def main() -> None:  # pragma: no cover - UIèµ·å‹•æ™‚ã«å®Ÿè¡Œ
    if st is None:
        raise RuntimeError("streamlit is not installed. Install it to run the UI.")

    st.set_page_config(page_title="LeadersBoard", layout="wide")
    api_url = os.getenv("API_URL", "http://api:8010")
    mlflow_url = os.getenv("MLFLOW_URL", "http://mlflow:5010")

    _render_submission_form(api_url, mlflow_url)
    st.divider()

    # Fragmentè‡ªå‹•æ›´æ–°ã‚’é©ç”¨ï¼ˆãŸã ã—å®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ãŒãªã„å ´åˆã¯APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    render_jobs_with_auto_refresh = st.fragment(run_every="5s")(_render_jobs)
    render_jobs_with_auto_refresh(api_url, mlflow_url)


if __name__ == "__main__":  # pragma: no cover
    main()
